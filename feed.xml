<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2025-11-12T12:50:04-08:00</updated><id>/feed.xml</id><title type="html">Kevin Clancy</title><subtitle></subtitle><author><name></name></author><entry><title type="html">Modelling MegaZeux</title><link href="/2025/11/04/modelling-megazeux.html" rel="alternate" type="text/html" title="Modelling MegaZeux" /><published>2025-11-04T08:00:00-08:00</published><updated>2025-11-04T08:00:00-08:00</updated><id>/2025/11/04/modelling-megazeux</id><content type="html" xml:base="/2025/11/04/modelling-megazeux.html"><![CDATA[<p>\(\newcommand{vrt}[2]{\left ( \begin{array}{l} #1 \\ #2 \end{array} \right )}\)
\(\newcommand{defeq}{\overset{\mathit{def}}{=}}\)</p>

<h1 id="introduction">Introduction</h1>

<p>Now that <a href="/2025/10/18/modelling-tic-tac-toe.html">we’ve modeled tic-tac-toe using dynamical systems</a>, let’s try modelling MegaZeux. Our goal isn’t to recreate every feature of the MegaZeux game creation system, but to understand its essence. Let’s explore what MegaZeux is <em>trying</em> to be, redesigning any features we find to be arbitrary or inelegant.</p>

<h2 id="concurrency-megazeux-and-the-real-world">Concurrency, MegaZeux, and the Real World</h2>

<p>In tic-tac-toe, players take turns making moves. But MegaZeux is a simulation of the real world. In the real world, all agents act concurrently.</p>

<p>As it turns out, MegaZeux does <em>not</em> faithfully reflect the concurrent nature of the real world. Robots execute in a turn-based manner every frame. The order that the robots execute in is decided by their position on the grid. It starts in the top-left corner, updating every robot it encounters as it moves right across the top row. Then it iterates across the second row, then the third, until it reaches the bottom-right corner of the game board.</p>

<p>This is awkward. It’s an arbitrary rule that a game developer needs to learn to explain the behavior of MegaZeux games. Consider two side-by-side robots. If both attempt walking one cell to the left on the same frame then both robots move. However, if both walk one cell to the right then only the right robot moves, because when the left robot walks right, it crashes into the right robot.</p>

<p>Our model, unlike MegaZeux, will allow all robots to act at once. The game stepper will evolve in the following fashion. First, it executes the initialization step:</p>

<ul>
  <li>The environment sends the initial game state to the robots; the game state includes positions of all robots, as well as wall positions. The environment sends \(1\) to each robot telling it that its last action succeeded, even though no such action exists; robots should be programmed to ignore this value. The robots use this information to update their states and store actions (\(\mathit{Idle}\), \(\mathit{North}\), \(\mathit{East}\), \(\mathit{South}\), \(\mathit{West}\)) to submit on the next step.</li>
</ul>

<p>Then, it executes steps of these two types in a loop:</p>

<ol>
  <li>
    <p>All robots concurrently transmit their stored action, computed on the previous step, to the environment. The robots also clear their stored actions. The environment executes the actions received from the robots to the best of its ability. If a robot proposes moving into a wall, off of the game board, or into a location where another robot currently is, then the move is not executed. If multiple robots attempt to move into the same cell then the environment randomly chooses one to move into the cell, committing the “losers” to their present positions. The environment stores the resulting state of the game board and booleans indicating whether each robot’s most recent action succeeded to submit back to the robots on the next step.</p>
  </li>
  <li>
    <p>(This is like the initialization step, but now the success values are meaningful.) The environment sends the current game state to the robots; the game state includes positions of all robots, as well as wall positions. The environment also sends to each robot a boolean indicating whether the robot’s most recently submitted action succeeded. The robots use this information to update their states and store actions to submit on the next step.</p>
  </li>
</ol>

<h2 id="non-deterministic-lenses-and-dynamical-systems">Non-deterministic lenses and dynamical systems</h2>

<p>According to our plan, when multiple robots attempt moving into the same cell, we randomly choose one to succeed. But this requires a feature beyond the scope of the technique of lenses and dynamical systems described in the previous blog post. Namely, non-determinism.</p>

<p>We’ll need to extend our definitions so that an environment can update its state non-deterministically. Recall that if \(\mathit{X}\) is a set then \(P X\) is the set of all subsets of \(X\), where \(P -\) is called the powerset operator. If we think of a set as a collection of possibilities, then what we want is a new formulation of dynamical systems, where the passback function has the type</p>

\[\mathit{State} \times \mathit{In} \to P \mathit{State}\]

<p>Instead of producing a successor state as output, it produces the set of all possible successor states. In <a href="https://www.davidjaz.com/Papers/DynamicalBook.pdf">Categorical Systems Theory</a>, this is called a <em>possibilistic</em> system. Before we define possibilistic systems, we must first define a possibilistic version of lenses.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>A <strong>\(P\)-lens</strong> \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) is a pair consisting of two functions:</p>
  <ul>
    <li>A passforward function \(f : A^+ \to B^+\)</li>
    <li>A passback function \(f^\sharp : A^+ \times B^- \to P A^-\)</li>
  </ul>

  <p>The arena \(\vrt{A^-}{A^+}\) is called the <strong>domain</strong> of \(\vrt{f^\sharp}{f}\) and the arena \(\vrt{B^-}{B^+}\) is called the <strong>codomain</strong> of \(\vrt{f^\sharp}{f}\).</p>
</blockquote>

<p>Now, we present the nondeterministic notion of dynamical systems.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>A <strong>possibilistic dynamical system</strong> is a \(P\)-lens of the form</p>

\[\vrt{\mathit{nextState}}{\mathit{output}} : \vrt{\mathit{State}}{\mathit{State}} \leftrightarrows \vrt{\mathit{In}}{\mathit{Out}}\]

  <p>That is, a dynamical system is a \(P\)-lens whose domain is an arena of the form \(\vrt{\mathit{State}}{\mathit{State}}\) for some set \(\mathit{State}\).</p>
</blockquote>

<p>We must also update the definitions of our composition operators.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>Given \(P\)-lenses \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) and
\(\vrt{g^\sharp}{g} : \vrt{B^-}{B^+} \leftrightarrows \vrt{C^-}{C^+}\) their <strong>composite</strong>
\(\vrt{g^\sharp}{g} \circ \vrt{f^{\sharp}}{f}\) is defined as \(\vrt{h^\sharp}{h}\), where</p>

  <ul>
    <li>\(h\) is defined as the function composite \(g \circ f\)</li>
    <li>\(h^\sharp\) is defined such that</li>
  </ul>

\[h^\sharp(a^+, c^-) \defeq \bigcup_{b^-~\in~g^\sharp(f(a^+), c^-)} f^\sharp(a^+, b^-)\]
</blockquote>

<p>We must also update our parallel composition operator.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>Given two lenses \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) and
\(\vrt{g^\sharp}{g} : \vrt{C^-}{C^+} \leftrightarrows \vrt{D^-}{D^+}\) we define their parallel
product
\(\vrt{f^\sharp}{f} \otimes \vrt{g^\sharp}{g} : \vrt{A^- \times C^-}{A^+ \times C^+} \leftrightarrows \vrt{B^- \times D^-}{B^+ \times D^+}\) is defined as the lens
\(\vrt{h^\sharp}{h}\), where</p>

\[h(a^+, c^+) \defeq (f(a^+), g(c^+))\]

  <p>and</p>

\[h^\sharp(a^+, c^+, b^-, d^-) \defeq \{ (a^-, c^-) \mid a^- \in f^\sharp(a^+, b^-),~c^- \in g^\sharp(c^+, d^-) \}\]
</blockquote>

<h1 id="the-model">The Model</h1>

<p>We call the game world that our robots traverse the <em>board</em>.
Our MegaZeux model is parameterized by three natural numbers:</p>

<ul>
  <li>n - the number of robots</li>
  <li>w - the width of the board in cells</li>
  <li>h - the height of the board in cells</li>
</ul>

<p>Recall that we write a natural number \(k\) in bold to denote the set of natural numbers that are less than it, i.e. \(\mathbf{k} \defeq \{ 0, \ldots, k-1 \}\) .</p>

<p>The set of board cell locations is then \(\mathbf{w} \times \mathbf{h}\). Our board state can then be defined as:</p>

\[\mathit{BoardState} \defeq \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^\mathbf{n}\]

<p>Elements of the first component \(\mathbf{2}^{\mathbf{w} \times \mathbf{h}}\) are functions mapping each board cell location to \(0\) if the cell is vacant and \(1\) if the cell contains a wall. Elements of the second component \((\mathbf{w} \times \mathbf{h})^{\mathbf{n}}\) map each robot identifier \(i\) to the cell location at which robot \(i\) is currently located.</p>

<p>Our environment takes steps of two types: receive and send. For send steps, we need to store a mapping from robot identifiers to booleans indicating whether the robot’s most recent action succeeded. Thus we define</p>

\[\mathit{StepType} \defeq 1 + \mathbf{2}^{\mathbf{n}}\]

<p>where the left summand \(1\) is used for receive steps and the right summand is for send steps.</p>

<p>The state of our environment \(\mathit{Env}\) is then defined as:</p>

\[\mathit{State}_{\mathit{Env}} \defeq \mathit{BoardState} \times \mathit{StepType}\]

<p>At each turn, a robot can act by either staying <strong>I</strong>dle or moving in one of the directions <strong>N</strong>orth, <strong>E</strong>ast, <strong>S</strong>outh, or <strong>W</strong>est. Therefore, we define the set of actions as:</p>

\[\mathit{Act} \defeq \{ I, N, E, S, W \}\]

<p>And the environment’s input, if any, is a map from each robot identifier \(i\) to the action submitted by robot \(i\) on a turn.</p>

\[\mathit{In}_{\mathit{Env}} \defeq (1 + \mathit{Act})^{\mathbf{n}}\]

<p>Since the robots only submit actions at every other step, we also include the summand \(1\) in the definition of \(\mathit{In}_{\mathit{Env}}\) to use on turns where the robots do not submit.</p>

<p>On every \(\mathit{Send}\) step, the environment must output to each robot a copy of the game state along with a boolean (an element of \(\mathbf{2}\)) indicating whether or not the robot’s most recently submitted action succeeded.</p>

\[\mathit{Out}_{\mathit{Env}} \defeq (1 + \mathit{BoardState} \times \mathbf{2})^{\mathbf{n}}\]

<p>The top-down perspective of the MegaZeux game stepper then looks as follows.</p>

<figure>
<img src="/assets/images/modelling-megazeux/stepper_2.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 1
</figcaption>
</figure>

<p>To help explain the diagram above, we introduce a notational convenience. Elements of function spaces like \(\mathit{Out}_{\mathit{Env}} = (1 + \mathit{BoardState} \times \mathbf{2})^{\mathbf{n}}\) are functions from robot identifiers (elements of \(\mathbf{n}\)) to output values. We can construct such a function using <em>lambda notation</em>: the expression \(\lambda i \in \mathbf{n} . (0, \ast)\) denotes the constant function that always returns \((0, \ast)\) regardless of which robot identifier \(i\) you pass in. If you’re familiar with programming, this is analogous to anonymous functions like Python’s <code class="language-plaintext highlighter-rouge">lambda i: (0, star)</code> or JavaScript’s <code class="language-plaintext highlighter-rouge">i =&gt; (0, star)</code>.</p>

<p>The diagram includes two combinational lenses labeled \(\mathit{t2f}\) and \(\mathit{f2t}\), which convert between n-ary Cartesian products and function spaces. When the \(n\) robots are composed in parallel, their collective output is an \(n\)-tuple (an element of the \(n\)-fold Cartesian product), but the environment expects a function from robot identifiers to actions. Similarly, the environment outputs a function mapping each robot to its board state and success value, but the parallel composition of robots expects an \(n\)-tuple. The \(\mathit{t2f}\) lens converts a tuple \((v_0, v_1, \ldots, v_{n-1})\) to the function \(\lambda i \in \mathbf{n} . v_i\), while \(\mathit{f2t}\) converts a function \(\phi : \mathbf{n} \to X\) to the tuple \((\phi(0), \phi(1), \ldots, \phi(n-1))\).</p>

<p>Note that, unlike the tic-tac-toe game stepper from the previous post, the MegaZeux stepper has no need for multiplexors and demultiplexors. In tic-tac-toe, the demultiplexor routes the board state to exactly one player per turn (based on whose turn it is), and the multiplexor collects moves from whichever player is active. In MegaZeux, all robots act simultaneously at each turn, so there is no selective routing.</p>

<h2 id="the-environment">The Environment</h2>

<p>Now that we’ve presented the structure of our possibilistic game stepper as a diagram, let’s define the subsystem \(\mathit{Env}\). It is defined as the possibilistic system</p>

\[\vrt{\mathit{nextState}_{\mathit{Env}}}{\mathit{output}_{\mathit{Env}}} : \vrt{\mathit{State}_{\mathit{Env}}}{\mathit{State}_{\mathit{Env}}} \leftrightarrows \vrt{\mathit{In}_{\mathit{Env}}}{\mathit{Out}_{\mathit{Env}}}\]

<p>The \(\mathit{output}_{\mathit{Env}}\) function replicates the wall and robot positions to all robots and distributes to each robot the result of its last action:</p>

\[\mathit{output}_{\mathit{Env}} : \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times (1 + \mathbf{2}^{\mathbf{n}}) \to (1 + \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathbf{2})^{\mathbf{n}}\]

\[\mathit{output}_{\mathit{Env}}(m, r, (0, \ast)) \defeq \lambda i \in \mathbf{n} . (0, \ast)\]

\[\mathit{output}_{\mathit{Env}}(m, r, (1, s)) \defeq \lambda i \in \mathbf{n} . (1, (m, r, s(i)))\]

<p>The \(\mathit{nextState}_{\mathit{Env}}\) passback function has type:</p>

\[\mathit{nextState}_{\mathit{Env}} : \mathit{State}_{\mathit{Env}} \times \mathit{In}_{\mathit{Env}} \to P\mathit{State}_{\mathit{Env}}\]

<p>Expanding the definitions:</p>

\[\mathit{nextState}_{\mathit{Env}} : (\mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times (1 + \mathbf{2}^{\mathbf{n}})) \times (1 + \mathit{Act})^{\mathbf{n}} \to P(\mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times (1 + \mathbf{2}^{\mathbf{n}}))\]

<p>We need a few helper functions. First, given a robot position map \(r\) and an action \(a \in \mathit{Act}\), we define \(\mathit{move}(r, i, a)\) to compute the proposed new position for robot \(i\):</p>

\[\mathit{move} : (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathbf{n} \times \mathit{Act} \to \mathbf{w} \times \mathbf{h}\]

\[\mathit{move}(r, i, a) \defeq \begin{cases}
(x, y) &amp; \text{if } a = I \\
(x, y - 1) &amp; \text{if } a = N \\
(x + 1, y) &amp; \text{if } a = E \\
(x, y + 1) &amp; \text{if } a = S \\
(x - 1, y) &amp; \text{if } a = W
\end{cases}\]

\[\text{where } (x, y) \defeq r(i)\]

<p>Next, we need to determine if a move is valid (doesn’t hit a wall, go out of bounds, or collide with a robot’s current position):</p>

\[\mathit{valid} : \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathbf{n} \times \mathit{Act} \to \mathbf{2}\]

\[\mathit{valid}(m, r, i, a) \defeq \begin{cases}
\mathit{true} &amp; \text{if } \mathit{move}(r,i,a) \in \mathbf{w} \times \mathbf{h} \\
&amp; \land~m(\mathit{move}(r,i,a)) = 0 \\
&amp; \land~\mathit{move}(r,i,a) \notin \{r(j) \mid j \in \mathbf{n}\} \\
\mathit{false} &amp; \text{otherwise}
\end{cases}\]

<p>Now we can define \(\mathit{nextState}_{\mathit{Env}}\). On a Send step in which the environment’s preconditions are satisfied (i.e., all robots provide no input), we transition back to Receive:</p>

\[\mathit{nextState}_{\mathit{Env}}((m, r, (1, s)), \lambda i \in \mathbf{n} . (0, \ast)) \defeq \{(m, r, (0, \ast))\}\]

<p>On a Receive step where the environment’s preconditions are satisified (i.e., all robots provide an action), we process the robot actions and non-deterministically resolve conflicts. Let \(a \in (1 + \mathit{Act})^{\mathbf{n}}\) be the input, where \(a(i) = (1, \alpha_i)\) for all \(i \in \mathbf{n}\) and some action \(\alpha_i\).</p>

<p>For each cell location \(\ell \in \mathbf{w} \times \mathbf{h}\), let \(\mathit{candidates}(\ell, m, r, a)\) denote the set of robots attempting to move to \(\ell\):</p>

\[\mathit{candidates} : (\mathbf{w} \times \mathbf{h}) \times \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathit{Act}^{\mathbf{n}} \to P\mathbf{n}\]

\[\mathit{candidates}(\ell, m, r, a) \defeq \{i \in \mathbf{n} \mid \mathit{valid}(m,r,i,a(i)) \land \mathit{move}(r,i,a(i)) = \ell\}\]

<p>Then we define the set of target locations that robots are attempting to move to:</p>

\[\mathit{targets} : \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathit{Act}^{\mathbf{n}} \to P(\mathbf{w} \times \mathbf{h})\]

\[\mathit{targets}(m, r, a) \defeq \{ \ell \in \mathbf{w} \times \mathbf{h} \mid |\mathit{candidates}(\ell, m, r, a)| \geq 1 \}\]

<blockquote>
  <p><strong>Definition</strong> For sets \(X\) and \(Y\), we write \(X \rightharpoonup Y\) for the set of partial functions from \(X\) to \(Y\),
defined as</p>

\[X \rightharpoonup Y \defeq \{ f \subseteq X \times Y \mid ((x,y) \in f \wedge (x,z) \in f) \Rightarrow y = z \}\]

  <p>For \(f \in X \rightharpoonup Y\), we write \(f(x) \! \downarrow\) and say that “\(f\) is defined at \(x\)” when there
exists a \(y \in Y\) with \((x,y) \in f\). We write \(f(x) \! \uparrow\) and say that “\(f\) is undefined at \(x\)” when no
such \(y \in Y\) exists. When \(f(x) \! \downarrow\), we write \(f(x)\) for the unique \(y \in Y\) with \((x,y) \in f\).</p>

  <p>We define \(\mathit{dom}(f)\), the domain of the partial function \(f : X \rightharpoonup Y\), as</p>

\[\mathit{dom}(f) \defeq \{ x \mid f(x) \! \downarrow \}\]
</blockquote>

<p>For each target, a <em>resolution</em> chooses one of the candidates to successfully move into the target.</p>

\[\mathit{resolutions} : \mathbf{2}^{\mathbf{w} \times \mathbf{h}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times \mathit{Act}^{\mathbf{n}} \to P(\mathbf{w} \times \mathbf{h} \rightharpoonup \mathbf{n})\]

\[\mathit{resolutions}(m, r, a) \defeq \{ q \in \mathbf{w} \times \mathbf{h} \rightharpoonup \mathbf{n} \mid \mathit{dom}(q) = \mathit{targets}(m,r,a) \wedge \forall \ell \in \mathit{dom}(q).~q(\ell) \in \mathit{candidates}(\ell, m, r, a)  \}\]

<p>Given a resolution \(q \in \mathit{resolutions}(m,r,a)\), we compute the new robot positions and success indicators. The function \(\mathit{nextr}\) computes the new position for each robot: a robot moves to its target cell if it won the resolution for that cell (i.e., the resolution chose it), otherwise it stays in place.</p>

\[\mathit{nextr} : \mathit{Act}^{\mathbf{n}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times (\mathbf{w} \times \mathbf{h} \rightharpoonup \mathbf{n}) \to (\mathbf{w} \times \mathbf{h})^{\mathbf{n}}\]

\[\mathit{nextr}(a,r,q)(i) \defeq \begin{cases}
\mathit{move}(r, i, a(i)) &amp; \text{if } q(\mathit{move}(r, i, a(i))) = i \\
r(i) &amp; \text{otherwise}
\end{cases}\]

<p>The function \(\mathit{success}\) indicates whether each robot’s action succeeded: a robot succeeds if its position changed, or if it chose to idle.</p>

\[\mathit{success} : \mathit{Act}^{\mathbf{n}} \times (\mathbf{w} \times \mathbf{h})^{\mathbf{n}} \times (\mathbf{w} \times \mathbf{h} \rightharpoonup \mathbf{n}) \to \mathbf{2}^{\mathbf{n}}\]

\[\mathit{success}(a,r,q)(i) \defeq \begin{cases}
1 &amp; \text{if } \mathit{nextr}(a,r,q)(i) \neq r(i) \vee a(i) = I \\
0 &amp; \text{otherwise}
\end{cases}\]

<p>We can now define the Receive step transition in terms of these helper functions:</p>

\[\mathit{nextState}_{\mathit{Env}}((m, r, (0, \ast)), a) \defeq \{ (m, \mathit{nextr}(a,r,q), (1, \mathit{success}(a,r,q))) \mid q \in \mathit{resolutions}(m, r, a) \}\]

<p>For any other combination of state and input (which–as violations of our environment’s preconditions–are never intended to arise), we return the empty set:</p>

\[\mathit{nextState}_{\mathit{Env}}(z, a) \defeq \emptyset\]

<h2 id="the-robots">The Robots</h2>

<p>For each robot identifier \(i \in \mathbf{n}\), we write \(\mathit{Robot}_i\) for the possibilistic system corresponding to robot \(i\).</p>

<p>We posit the existence of a set \(\Sigma_i\) containing the <em>mental state</em> of robot \(i\). A value of \(\Sigma_i\) might contain a program counter for the script robot \(i\) is currently running, and it might contain private data members as well. For distinct \(i,j \in \mathbf{n}\) the sets \(\Sigma_i\) and \(\Sigma_j\) are not required to be equal and are typically distinct.</p>

<p>In addition to mental state, the state of robot \(i\) also contains <em>administrative state</em>. The administrative state \(S\), which is uniform across all robots, synchronizes the robot with the environment and stages actions to transmit to the environment.</p>

\[S \defeq 1 + \mathit{Act}\]

<p>The value \((0,\ast) \in S\) means that the environment is currently in a \(\mathit{Submit}\) state. This means that the robots are currently receiving the board state and their success values. The value \((1, a) \in S\) means that the environment is currently in a \(\mathit{Receive}\) state. The value \(a\) is the action computed by the robot at the previous step, which has been stored in preparation for transmission at the current step.</p>

<p>Then the state set of robot \(i\) is defined as:</p>

\[\mathit{State}_{\mathit{Robot}_i} \defeq S \times \Sigma_i\]

<p>Figure 1 above shows us the input and output sets shared by the \(n\) robots:</p>

\[\mathit{In}_{\mathit{Robot}_i} \defeq 1 + (\mathit{BoardState} \times \mathbf{2})\]

\[\mathit{Out}_{\mathit{Robot}_i} \defeq 1 + \mathit{Act}\]

<p>Note that \(\mathit{Out}_{\mathit{Robot}_i} = S\).</p>

<p>Now, we must define \(\mathit{Robot}_i\) as a possibilistic lens:</p>

\[\mathit{Robot}_i : \vrt{\mathit{State}_{\mathit{Robot}_i}}{\mathit{State}_{\mathit{Robot}_i}} \leftrightarrows \vrt{\mathit{In}_{\mathit{Robot}_i}}{\mathit{Out}_{\mathit{Robot}_i}} \defeq \vrt{nextState_{\mathit{Robot}_i}}{\mathit{output}_{\mathit{Robot}_i}}\]

<p>where we define</p>

\[\mathit{output}_{\mathit{Robot}_i} : S \times \Sigma_i \to 1 + \mathit{Act}\]

\[\mathit{output}_{\mathit{Robot}_i}(s, \sigma) \defeq s\]

<p>and</p>

\[\mathit{nextState}_{\mathit{Robot}_i} : S \times \Sigma_i \times (1 + \mathit{BoardState} \times \mathbf{2}) \to P(S \times \Sigma_i)\]

<p>We posit the existence of a function \(\phi_i : \Sigma_i \times \mathit{BoardState} \times \mathbf{2} \to \mathit{Act} \times \Sigma_i\) which, given robot \(i\)’s mental state, the current board state, and whether its last action succeeded, computes the next action and updates the mental state.</p>

<p>When in the “robot receiving” state \((0, *)\), the robot expects board state as input, and uses \(\phi\) to compute its new state and action.</p>

\[\mathit{nextState}_{\mathit{Robot}_i}((0, \ast), \sigma, (1, (b, s))) \defeq \{((1, a), \sigma')\}\]

\[\text{where } (a, \sigma') = \phi_i(\sigma, b, s)\]

<p>When in the “robot sending” state \((1, a)\), the robot expects empty input and transitions back to the “robot receiving” state.</p>

\[\mathit{nextState}_{\mathit{Robot}_i}((1, a), \sigma, (0, \ast)) \defeq \{((0, \ast), \sigma)\}\]

<p>For any other combination of state and input (precondition violations), we return the empty set:</p>

\[\mathit{nextState}_{\mathit{Robot}_i}(z, \sigma, x) \defeq \emptyset\]

<h2 id="wiring-things-up">Wiring things up</h2>

<p>We now have all the pieces to assemble our game stepper: the environment \(\mathit{Env}\) and the \(n\) robots \(\mathit{Robot}_0, \ldots, \mathit{Robot}_{n-1}\). To create the full system, we need to connect the robots layer to the environment layer using composition.</p>

<p>The robots layer is formed by composing all robots in parallel:</p>

\[\mathit{Robots} \defeq \mathit{Robot}_0 \otimes \mathit{Robot}_1 \otimes \cdots \otimes \mathit{Robot}_{n-1}\]

<p>We convert to the environment’s input set by post-composing by the \(\mathit{t2f}\) combinational lens.</p>

\[A \defeq \mathit{t2f} \circ \mathit{Robots}\]

<p>We convert from the environment’s output set to the players’ input set by postcomposing with \(\mathit{f2t}\)</p>

\[B \defeq \mathit{f2t} \circ \mathit{Env}\]

<p>The signatures of \(A\) and \(B\) are</p>

\[A : \vrt{\mathit{State_{\mathit{Robot}_1}} \times \cdots \times \mathit{State}_{\mathit{Robot}_n}}{\mathit{State_{\mathit{Robot}_1}} \times \cdots \times \mathit{State}_{\mathit{Robot}_n}} \leftrightarrows \vrt{(1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2})}{(1 + \mathit{Act})^{\mathbf{n}}}\]

<p>and</p>

\[B : \vrt{\mathit{State_{\mathit{Env}}}}{\mathit{State}_{\mathit{Env}}} \leftrightarrows \vrt{(1 + \mathit{Act})^{\mathbf{n}}}{(1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2})}\]

<p>We juxtapose them with the parallel product:</p>

\[A \otimes B : \vrt{\mathit{State_{\mathit{Robot}_1}} \times \cdots \times \mathit{State}_{\mathit{Robot}_n} \times \mathit{State}_{\mathit{Env}}}{\mathit{State_{\mathit{Robot}_1}} \times \cdots \times \mathit{State}_{\mathit{Robot}_n} \times \mathit{State}_{\mathit{Env}}} \leftrightarrows \vrt{(1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2}) \times (1 + \mathit{Act})^{\mathbf{n}}}{(1 + \mathit{Act})^{\mathbf{n}} \times (1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2})}\]

<p>which is depicted by the following diagram</p>

<figure>
<img src="/assets/images/modelling-megazeux/ab-juxtapose.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 2
</figcaption>
</figure>

<p>We wire \(A\) and \(B\) together by post-composing \(A \otimes B\) with a wiring lens that creates the feedback loop. The wiring lens must take the output of \(A \otimes B\) (which has \(A\)’s output followed by \(B\)’s output) and route it appropriately: \(B\)’s output should feed into \(A\)’s input, and \(A\)’s output should feed into \(B\)’s input.</p>

\[\vrt{w^\sharp}{w} : \vrt{(1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2}) \times (1 + \mathit{Act})^{\mathbf{n}}}{(1 + \mathit{Act})^{\mathbf{n}} \times (1 + \mathit{BoardState} \times \mathbf{2}) \times \underset{n}{\cdots} \times (1 + \mathit{BoardState} \times \mathbf{2})} \leftrightarrows \vrt{1}{1}\]

<p>where the passforward function \(w\) is defined as:</p>

\[w(a, b_0, b_1, \ldots, b_{n-1}) \defeq \ast\]

<p>This function simply discards both outputs, as the system is closed (there is no external environment to communicate with).</p>

<p>The passback function \(w^\sharp\) creates the feedback connections:</p>

\[w^\sharp(a, b_0, b_1, \ldots, b_{n-1}, \ast) \defeq \{(b_0, b_1, \ldots, b_{n-1}, a)\}\]

<p>The complete game stepper is then:</p>

\[\mathit{Stepper} \defeq \vrt{w^\sharp}{w} \circ (A \otimes B)\]

<h1 id="conclusion">Conclusion</h1>

<p>Now we’re getting somewhere. We have a game stepper that almost resembles MegaZeux. Like MegaZeux, it has a varying number of robots driven by distinct scripts. Also like MegaZeux, these robots are located on a 2D grid and move on the grid by submitting requests to an environment. Instead of executing the robot scripts in sequence, our model diverges from MegaZeux by executing the scripts of all robots concurrently at each frame. This more accurately reflects the real world and prevents a game from confusing developers with hidden execution ordering rules.</p>

<h2 id="looking-ahead">Looking Ahead</h2>

<p>Recall our original checklist of features:</p>

<ul>
  <li>✅ A robot performs physical actions by submitting requests to an environment. The environment decides whether to honor these requests.</li>
  <li>✅ A robot has internal state, but it’s a purely “mental” state that is used to make decisions. Physical properties of the robot are stored in the environment’s internal state.</li>
  <li>❌ A robot may send a message to another robot, which represents information sent along some physical communication medium.</li>
</ul>

<p>We still need to implement the last one. Now that we’ve extended our dynamical systems formalism to <em>possibilistic</em> dynamical systems capable of modelling non-deterministic behavior, robots can process all messages received on the previous frame in any non-deterministically chosen order.</p>

<p>To refresh your memory, here is the sample pseudo-code of robot message passing that I presented in the previous post.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// When the player switches off the fuse box, this channel notifies all subscribers.
channel fuse_box_off : 1;

robot roy {
  receives on fuse_box_off;

  state working {
    handler fuse_box_off (_ : 1) = {
      set_state(fix_fusebox);
    }
  }

  state fix_fusebox {
    ...
  }
}

robot fuse_box {
  sends on fuse_box_off;

  state on {
    handler on_player_touch (_ : 1) = {
      send fuse_box_off(*);
      set_state(off);
    }
  }

  state off {
    ...
  }
}
</code></pre></div></div>

<p>Diagramatically, each robot \(R\) appears as a rectangle representing a possibilistic dynamical system. Now, in addition to an input wire transmitting elements of the \(\mathit{GameState}\) set, the system \(R\) also has an input wire for each channel that it subscribes to as a receiver. In addition to the output wire transmitting elements of the set \(\mathit{Act}\) of actions, it also has one output wire for each channel \(R\) subscribes to as a sender.</p>

<p>So, for example, the \(\mathit{Roy}\) system has two input wires: one transmits observations of \(\mathit{GameState}\) sent from the environment, and the other transmits the collection of all messages sent along the \(\mathit{fuse\_box\_off}\) channel during a single frame. Because \(\mathit{Roy}\) does not subscribe to any channels as a sender, it has only an \(\mathit{Act}\) output wire.</p>

<figure>
<img src="/assets/images/modelling-megazeux/roy-example.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 3
</figcaption>
</figure>

<p>And likewise for the \(\mathit{FuseBox}\) system.</p>

<figure>
<img src="/assets/images/modelling-megazeux/fuse-box-solo.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 4
</figcaption>
</figure>

<p>Now, you might wonder why the channel wires are labelled with \(M_{\mathit{fin}} 1\) even though the \(\mathit{fuse\_box\_off}\) channel was declared with type \(1\). The reason is that \(1\) is the type of the individual messages that the channel transmits, but the channel may transmit multiple messages from multiple sender robots on the same frame. Because we’ve decided that distinct messages sent on the same frame are sent “at the same instant” (more precisely, they’re sent within such a small interval that determining their order is too fine-grained to fall within the scope of our game system), the channel wire must transmit an unordered collection of messages rather than a single message. Given a set \(X\), the elements of the set \(P X\) are unordered collections of the set \(X\). But in elements of \(P X\) (subsets of \(X\)), all elements are unique. This is not appropriate for message collections, because multiple robots, or even a single robot, can transmit the same message multiple times along a channel on a single frame. Furthermore, if \(X\) is an infinite set, say the set \(\mathbb N = \{ 0, 1, 2, \ldots \}\) of natural numbers, then its subsets can be infinite as well; collections of messages must be finite so that a robot can sequentially process all of them.</p>

<blockquote>
  <p><strong>Definition</strong> Given a set \(X\), the set \(M_{\text{fin}}X\) of <em>finite multisets</em> of \(X\) is defined as follows:</p>

\[M_{\text{fin}}X \defeq \{ f : X \to \mathbb{N} \mid \text{finite support} \}\]

  <p>where a function has finite support if \(\{x \in X \mid f(x) &gt; 0\}\) is finite. A function \(f : X \to \mathbb N\) represents a multiset where each element \(x \in X\) appears \(f(x)\) times.</p>
</blockquote>

<p>To leave things off, the following informal diagram demonstrates how message channels are wired together in the game stepper system.</p>

<figure>
<img src="/assets/images/modelling-megazeux/channel-wiring.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 5
</figcaption>
</figure>

<p>For each channel, all of the sender wires are directed into a combinational lens called \(\mathit{dist}\). This lens takes the union of the multisets and duplicates this union along each of the wires going into the receivers of the channel. The receivers store the multiset internally, waiting for the next frame to process it and replace it. We’ll cover how this works in more detail in a future post</p>]]></content><author><name></name></author><summary type="html"><![CDATA[\(\newcommand{vrt}[2]{\left ( \begin{array}{l} #1 \\ #2 \end{array} \right )}\) \(\newcommand{defeq}{\overset{\mathit{def}}{=}}\)]]></summary></entry><entry><title type="html">Modelling Tic-Tac-Toe</title><link href="/2025/10/18/modelling-tic-tac-toe.html" rel="alternate" type="text/html" title="Modelling Tic-Tac-Toe" /><published>2025-10-18T09:35:00-07:00</published><updated>2025-10-18T09:35:00-07:00</updated><id>/2025/10/18/modelling-tic-tac-toe</id><content type="html" xml:base="/2025/10/18/modelling-tic-tac-toe.html"><![CDATA[<p>\(\newcommand{vrt}[2]{\left ( \begin{array}{l} #1 \\ #2 \end{array} \right )}\)
\(\newcommand{defeq}{\overset{\mathit{def}}{=}}\)
\(\newcommand{am}{\text{a.m.}}\)
\(\newcommand{pm}{\text{p.m.}}\)</p>

<h1 id="overview">Overview</h1>

<p>This post is a continuation of <a href="/posts/2025/07/11/towards-mathematical-model.html">Towards a Mathematical Model of Computer Games</a>. Unlike that post, this one is focused on mathematical rigor rather than motivation. Rather than defining a mathematical model of a MegaZeux game, it pursues the less ambitious goal of defining a mathematical model of tic-tac-toe. The game tic-tac-toe shares some common characteristics with a MegaZeux game.</p>

<p>The game involves two players. Each of these players is analogous to a MegaZeux robot, and the game board plays the role of the environment. The players repeatedly make requests to the board to alter its state. The board may or may not honor those requests depending on whether they obey its “laws of physics”.</p>

<p>The two players together with their environment will form a <em>closed system</em>, i.e. a set \(\mathit{GameState}\) with an update function</p>

\[\mathit{nextState} : \mathit{GameState} \to \mathit{GameState}\]

<p>Or equivalently, a set of two functions, using \(1 = \{ \ast \}\) as both the input and output sets:</p>

\[\mathit{output} : \mathit{GameState} \to 1\]

<p>and</p>

\[\mathit{nextState} : 1 \times \mathit{GameState} \to \mathit{GameState}\]

<p>We will construct this closed system out of open systems such as the players. The players are open systems that take observations of the board state as inputs and produce move choices as outputs. As a rough first approximation, a player can be diagrammed as follows:</p>

<center>
<img src="/assets/images/gameloop/ttt-player.drawio.png" />
</center>

<p>The above system is considered <em>open</em> because its input and output are not one-element sets; they contain actual information that must be received from and sent to unspecified destinations. Each turn, an element of BoardState is received as input. The player uses the current board state, possibly along with the player’s own internal state, to decide a move to submit to the board.</p>

<p>Now, let’s develop a formalism that allows us to compose complex systems from simpler systems.</p>

<h1 id="lenses">Lenses</h1>

<p>We model open systems mathematically using a construct called <em>lenses</em>. I learned about lenses from <a href="https://www.davidjaz.com/Papers/DynamicalBook.pdf">Categorical Systems Theory</a>, which I highly recommend. In the interest of self-containment, I will rehash the fundamentals of lenses now.</p>

<h2 id="definitions">Definitions</h2>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>An <strong>arena</strong> \(\vrt{A^-}{A^+}\) is a pair consisting of two sets \(A^-\) and \(A^+\).</p>
</blockquote>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>A <strong>lens</strong> \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) is a pair consisting of two functions:</p>
  <ul>
    <li>A passforward function \(f : A^+ \to B^+\)</li>
    <li>A passback function \(f^\sharp : A^+ \times B^- \to A^-\)</li>
  </ul>

  <p>The arena \(\vrt{A^-}{A^+}\) is called the <strong>domain</strong> of \(\vrt{f^\sharp}{f}\) and the arena \(\vrt{B^-}{B^+}\) is called the <strong>codomain</strong> of \(\vrt{f^\sharp}{f}\).</p>
</blockquote>

<p>The passforward function of a lens can be viewed as sending information “downstream” and the passback function can be viewed as sending information “upstream”. One particularly important type of lens is a discrete dynamical system.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>A <strong>discrete dynamical system</strong> (or <strong>dynamical system</strong> for short) is a lens of the form</p>

\[\vrt{\mathit{nextState}}{\mathit{output}} : \vrt{\mathit{State}}{\mathit{State}} \leftrightarrows \vrt{\mathit{In}}{\mathit{Out}}\]

  <p>That is, a dynamical system is a lens whose domain is an arena of the form \(\vrt{\mathit{State}}{\mathit{State}}\) for some set \(\mathit{State}\).</p>
</blockquote>

<p>Above, we consider \(\mathit{State}\) the type of our dynamical system’s internal state, \(\mathit{In}\) the type of its input, and \(\mathit{Out}\) the type of its output. Expanding the definition of lens, we see that</p>
<ul>
  <li>\(\mathit{nextState} : \mathit{State} \times \mathit{In} \to \mathit{State}\) is a function that takes a pair of a “current” state and an input to a “next” state.</li>
  <li>\(\mathit{output} : \mathit{State} \to \mathit{Out}\) is a function that takes a state to an output.</li>
</ul>

<p>This matches the intuitive structure of game engines that I presented previously. Those familiar with digital logic may know the distinction between <em>Moore machines</em> and <em>Mealy machines</em>. The output of a Mealy machine may depend both on its input and its current state, whereas the output of a Moore machine may only depend on its current state. In this sense, a dynamical system is like a Moore machine rather than a Mealy machine: before its input can affect its output, it must store the input in its state as an intermediate step. This can be a bit awkward sometimes, but it’s not a fundamental problem.</p>

<p>A dynamical system \(S : \vrt{\mathit{State}_S}{\mathit{State}_S} \leftrightarrows \vrt{\mathit{In}_S}{\mathit{Out}_S}\) can be depicted as follows.</p>

<figure>
<img src="/assets/images/gameloop/discrete-dynamical-system.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>
Figure 1
</figcaption>
</figure>

<p>Note that the set \(\mathit{State}_S\) does not appear in the diagram, because it does not affect the systems that \(S\) interacts with.</p>

<p>If the codomain of one lens matches the domain of another then we can compose them together.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>Given lenses \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) and
\(\vrt{g^\sharp}{g} : \vrt{B^-}{B^+} \leftrightarrows \vrt{C^-}{C^+}\) their <strong>composite</strong>
\(\vrt{g^\sharp}{g} \circ \vrt{f^{\sharp}}{f}\) is defined as \(\vrt{h^\sharp}{h}\), where</p>

  <ul>
    <li>\(h\) is defined as the function composite \(g \circ f\)</li>
    <li>\(h^\sharp\) is defined such that \(h^\sharp(a^+, c^-) \defeq f^\sharp(a^+, g^\sharp(f(a^+), c^-))\)</li>
  </ul>
</blockquote>

<p>We also have a parallel composition operator on lenses.</p>

<blockquote>
  <p><strong>Definition</strong></p>

  <p>Given two lenses \(\vrt{f^\sharp}{f} : \vrt{A^-}{A^+} \leftrightarrows \vrt{B^-}{B^+}\) and
\(\vrt{g^\sharp}{g} : \vrt{C^-}{C^+} \leftrightarrows \vrt{D^-}{D^+}\) we define their parallel
product
\(\vrt{f^\sharp}{f} \otimes \vrt{g^\sharp}{g} : \vrt{A^- \times C^-}{A^+ \times C^+} \leftrightarrows \vrt{B^- \times D^-}{B^+ \times D^+}\) is defined as the lens
\(\vrt{h^\sharp}{h}\), where</p>

\[h(a^+, c^+) \defeq (f(a^+), g(c^+))\]

  <p>and</p>

\[h^\sharp(a^+, c^+, b^-, d^-) \defeq (f^\sharp(a^+, b^-), g^\sharp(c^+, d^-))\]
</blockquote>

<p>Given dynamical systems</p>

\[S : \vrt{\mathit{State}_S}{\mathit{State}_S} \leftrightarrows \vrt{\mathit{In}_S}{\mathit{Out}_S}\]

<p>and</p>

\[T : \vrt{\mathit{State}_T}{\mathit{State}_T} \leftrightarrows \vrt{\mathit{In}_T}{\mathit{Out}_T}\]

<p>their parallel product</p>

\[S \otimes T : \vrt{\mathit{State}_S \times \mathit{State}_T}{\mathit{State}_S \times \mathit{State}_T} \leftrightarrows \vrt{\mathit{In}_S \times \mathit{In}_T}{\mathit{Out}_S \times \mathit{Out}_T}\]

<p>can be depicted by juxtaposing the two dynamical systems.</p>

<figure>
<img src="/assets/images/gameloop/parallel-product.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 2</figcaption>
</figure>

<h2 id="example">Example</h2>

<p>Here is an example of a dynamical system from <a href="https://www.davidjaz.com/Papers/DynamicalBook.pdf">Categorical Dynamical Systems</a>. Define the set</p>

\[\mathit{Hour} \defeq \{ 1,2,3,4,5,6,7,8,9,10,11,12 \}\]

<p>We define a dynamical system</p>

\[\mathit{Clock} : \vrt{\mathit{Hour}}{\mathit{Hour}} \leftrightarrows \vrt{1}{\mathit{Hour}} \defeq \vrt{f^\sharp}{f}\]

<p>where \(f\) is the identity function</p>

\[f(x) \defeq x\]

<p>and</p>

\[f^\sharp(h, \ast) \defeq \begin{cases}
1 &amp; \text{  if } h = 12 \\
h + 1 &amp; \text{  otherwise}
\end{cases}\]

<p>This system represents a wall clock, which takes no external input and advances one hour forward at each step.</p>

<figure>
<img src="/assets/images/gameloop/clock.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 3</figcaption>
</figure>

<p>Note that we don’t need to draw an incoming edge; because the input is \(1 = \{ \ast \}\), it transmits only one possible choice of value \(\ast\). So instead of receiving input from an external source, \(\mathit{Clock}\) can fabricate the value \(\ast\) at every step, knowing it is the correct choice.</p>

<p>The above clock does not distinguish between \(\am\) and \(\pm\) To fix this,
we define a dynamical system called \(Meridiem\) that shifts between \(\am\) and \(\pm\) We first define the set
\(\am/\pm \defeq \{ \am, \pm \}\)
Then we define</p>

\[\mathit{Meridiem} : \vrt{\am/\pm}{\am/\pm} \leftrightarrows \vrt{\mathit{Hour}}{\am/\pm} \defeq \vrt{f^\sharp}{f}\]

<p>where</p>

\[f(m) \defeq m\]

<p>and</p>

\[f^\sharp(\am,h) \defeq \begin{cases}
\pm &amp; \text{if } h = 11 \\
\am &amp; \text{otherwise}
\end{cases}\]

\[f^\sharp(\pm,h) \defeq \begin{cases}
\am &amp; \text{if } h = 11 \\
\pm &amp; \text{otherwise}
\end{cases}\]

<p>Now we need “wire together” the \(\mathit{Clock}\) and \(\mathit{Meridiem}\) systems. As a first step, we take their paralell product.</p>

\[\mathit{Clock} \otimes \mathit{Meridiem} :
\vrt{\mathit{Hour} \times \am/\pm}{\mathit{Hour} \times \am/\pm} \leftrightarrows \vrt{1 \times \mathit{Hour}}{\mathit{Hour} \times \am/\pm}\]

<figure>
<img src="/assets/images/gameloop/clock-meridiem.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 4</figcaption>
</figure>

<p>To feed the output of \(\mathit{Clock}\) into \(\mathit{Meridiem}\), we use composition, which
can be depicted as nesting.</p>

<figure>
<img src="/assets/images/gameloop/compose-clock.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 5</figcaption>
</figure>

<p>The inner dotted box is the parallel product \(\mathit{Clock} \otimes \mathit{Meridiem}\). The outer dotted box is the fully wired system. The section between the two boxes depicts a new lens</p>

\[\vrt{w^\sharp}{w} : \vrt{1 \times \mathit{Hour}}{\mathit{Hour} \times \am/\pm} \leftrightarrows \vrt{1}{\mathit{Hour} \times \am/\pm}\]

<p>defined such that</p>

\[w(h,m) \defeq (h,m)\]

<p>and</p>

\[w^\sharp(h, m, \ast) \defeq (\ast, h)\]

<p>The fully wired system, which we shall call \(\mathit{Clock}'\) is then defined as</p>

\[\mathit{Clock}' : \vrt{\mathit{Hour} \times \am/\pm}{\mathit{Hour} \times \am/\pm} \leftrightarrows \vrt{1}{\mathit{Hour} \times \am/\pm} \defeq \vrt{w^\sharp}{w} \circ (\mathit{Clock} \otimes \mathit{Meridiem})\]

<h2 id="combinational-systems">Combinational Systems</h2>

<p>Suppose that we want to translate the output of the \(\mathit{Clock}'\) system above to
24-hour time, also known as “military time”, instead of \(\am/\pm\) Let</p>

\[\mathit{Hour24} \defeq \{ 0, 1, 2, \ldots, 23 \}\]

<p>We need to “post-compose” a function \(f : \mathit{Hour} \times \am/\pm \to \mathit{Hour24}\) after
the \(\mathit{Clock}'\) system, where \(f\) is defined as follows:</p>

\[f(h, \am) \defeq \begin{cases}
0 &amp; \text{if } h = 12 \\
h &amp; \text{otherwise}
\end{cases}\]

\[f(h, \pm) \defeq \begin{cases}
12 &amp; \text{if } h = 12 \\
12 + h &amp; \text{otherwise}
\end{cases}\]

<p>Such a post-composition is depicted below</p>

<figure>
<img src="/assets/images/gameloop/24-conversion.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 6</figcaption>
</figure>

<p>Note that \(f\) is just a function, not a dynamical system with state.</p>

<p>In digital logic, a circuit that stores state is known as sequential, whereas a circuit that
merely computes a function is called combinational. The function \(f\) above, having no internal state, is combinational. We can post-compose a dynamical system by a combinational system using lens combination.</p>

<p>Without loss of generality, let \(\mathit{Out}_0 \defeq \mathit{Hour} \times \am/\pm\), let
\(\mathit{Out}_1 \defeq \mathit{Hour24}\), and let \(\mathit{In} \defeq 1\).
Then this lens should translate the system’s output using a function \(f : \mathit{Out}_0 \to \mathit{Out}_1\)  but leave the input \(\mathit{In}\) unchanged. Hence we define it as</p>

\[\vrt{\pi_1}{f} : \vrt{\mathit{In}}{\mathit{Out_0}} \leftrightarrows \vrt{\mathit{In}}{\mathit{Out}_1}\]

<p>where \(\pi_1 : \mathit{Out_0} \times \mathit{In} \to \mathit{In}\) is the projection of the second component \((o,i) \mapsto i\).</p>

<p>We then obtain our military time clock as</p>

\[\mathit{MilitaryClock} \defeq \vrt{\pi_1}{f} \circ \mathit{Clock'}\]

<h2 id="demultiplexors">Demultiplexors</h2>

<p>Imagine a turn-based board game with multiple players. At each turn, we want to provide exactly one player with the state of the board so that they can make an informed move. The challenge is to send a payload value along a different wire depending on some selector value, and to send “nothing” along all other wires. More precisely, we need a combinational circuit, called a <em>demultiplexor</em>, that takes two inputs</p>

<ul>
  <li>The <em>payload</em>, whose type \(\mathit{Payload}\) may vary</li>
  <li>The <em>selector</em> of type <strong>n + 1</strong>, deciding which, if any, of \(n\) output destinations to transmit the payload to</li>
</ul>

<p>The demultiplexor circuit has \(n\) different output wires. Their type is not quite \(\mathit{Payload}\); each wire may contain a value of type \(\mathit{Payload}\) or, if it has not been selected, it may contain “no information” of type \(1\).</p>

<p>To express the set of values that each belong to exactly one of the disjoint sets \(\mathit{Payload}\) or \(1\) we need to use a set theoretic operation called the <em>sum</em>, which is not as well known as its evil twin the Cartesian product.</p>

<blockquote>
  <p><strong>Definition</strong> Given sets \(X\) and \(Y\), their sum \(X + Y\) is defined as</p>

\[X + Y \defeq \{ (0,x) \mid x \in X \} \cup \{ (1,y) \mid y \in Y \}\]
</blockquote>

<p>By tagging values with either \(0\) or \(1\), we ensure that the elements of the two operands are treated as mutually exclusive. It may be instructive to compare the set \(1 = 1 \cup 1\) with the set \(1 + 1\).</p>

<p>While we’re at it, let’s define another set-theoretic operation.</p>

<blockquote>
  <p><strong>Definition</strong> Given sets \(X\) and \(Y\), \(X^Y\) is defined as the set of functions from \(Y\)
to \(X\). In other words, \(X^Y\) is a synonym for \(Y \to X\).</p>
</blockquote>

<p>Now we are ready to formally define the notion of demultiplexor circuits.</p>

<blockquote>
  <p><strong>Definition</strong> The <strong>demultiplexor</strong> \(\mathit{demux}(\mathit{In}, X, n)\) is the combinational lens</p>

\[\vrt{\pi_1}{f} : \vrt{\mathit{In}}{X \times (\mathbf{n + 1})} \leftrightarrows \vrt{\mathit{In}}{(1 + X)^\mathbf{n}}\]

  <p>where \(f : X \times (\mathbf{n + 1}) \to (1 + X)^\mathbf{n}\) is defined such that</p>

\[f(x, m)(k) \defeq \begin{cases}
(1,x) &amp; \text{ if } m = k \\
(0,\ast) &amp; \text{ if } m \neq k
\end{cases}\]

  <p>and \(\pi_1 : (X \times (\mathbf{n + 1})) \times \mathit{In} \to \mathit{In}\) is the second projection function</p>

\[\pi_1((x, m), i) \defeq i\]
</blockquote>

<p>Thus, the demultiplexor \(\mathit{demux}(\mathit{In}, X,n)\) allows us to either</p>

<ul>
  <li><em>Select</em> some \(m \in \mathbf{n}\) such that \((1,x)\) is transmitted along the \(m^{\mathit{th}}\) output wire and \((0,\ast)\) is transmitted along all other output wires.</li>
  <li>Or, if \(m = n\), then transmit \((0,\ast)\) along all wires.</li>
</ul>

<p>\(\mathit{demux}(\mathit{In}, X,n)\) is depicted below, where we’ve elided all but the first and last of the \(n\) output wires.</p>

<figure>
<img src="/assets/images/gameloop/demux.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Diagram 7</figcaption>
</figure>

<p>Note that \(\mathit{demux}(\mathit{In}, X, n)\) can only be post-composed with a dynamical system whose input set is \(\mathit{In}\). When a demultiplexor is post-composed with a system \(S : \vrt{\mathit{State}_S}{\mathit{State}_S} \leftrightarrows \vrt{\mathit{In}_S}{\mathit{Out}_S}\), we elide the \(\mathit{In}\) argument from \(\mathit{demux}\), instead inferring from context that \(\mathit{In} = \mathit{In}_S\):</p>

<figure>
<img src="/assets/images/gameloop/demux-postcompose.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 8</figcaption>
</figure>

<h2 id="multiplexors">Multiplexors</h2>

<p>Assume \(n\) inputs of type \((1 + X)\), and further assume that we expect at most one input to have the form \((1, x)\) while the others have the form \((0,\ast)\). We want a combinational lens that produces a single output of type \(1 + X\), and which forwards \((1,x)\) if a single input has the form \((1,x)\) and forwards \((0,x)\) otherwise.</p>

<blockquote>
  <p><strong>Definition</strong> The <strong>multiplexor</strong> \(\mathit{mux}(\mathit{In}, X, n)\) is the combinational lens</p>

\[\vrt{\pi_1}{f} : \vrt{\mathit{In}}{(1 + X)^\mathbf{n}} \leftrightarrows \vrt{\mathit{In}}{1 + X}\]

  <p>where \(f : (1 + X)^\mathbf{n} \to (1 + X)\) is defined as</p>

\[f(\phi) \defeq \begin{cases}
\phi(m) &amp; \text{if there exists a unique } m \in \mathbf{n} \text{ such that } \phi(m) = (1, x) \text{ for some } x \\
(0,\ast) &amp; \text{otherwise}
\end{cases}\]

  <p>and \(\pi_1 : (1 + X)^\mathbf{n} \times \mathit{In} \to \mathit{In}\) is the second projection function</p>

\[\pi_1(\phi, i) \defeq i\]
</blockquote>

<figure>
<img src="/assets/images/gameloop/mux.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 9</figcaption>
</figure>

<p>Similar to \(\mathit{demux}\), we typically infer the \(\mathit{In}\) argument.</p>

<figure>
<img src="/assets/images/gameloop/mux-postcompose.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 10</figcaption>
</figure>

<h1 id="tic-tac-toe">Tic-tac-toe</h1>

<p>Now we use the dynamical system techniques described above to model the game of tic-tac-toe.
We do not model any notion of a winning condition, but instead focus on the evolution of the game over time, where two agents (players) influence the environment (the board) by submitting moves in a turn-based fashion.</p>

<h2 id="overview-1">Overview</h2>

<p>To model the board, we first need a notion of cell locations. Let each bold natural number
\(\mathbf{n}\) denote the set of natural numbers less than it, i.e.
\(\mathbf{n} \defeq \{ 0, 1, \ldots, n-1 \}\). A location on a tic-tac-toe board consists of an
x-coordinate and a y-coordinate, so we define the set \(\mathit{Loc}\) of locations as</p>

\[\mathit{Loc} \defeq \mathbf{3} \times \mathbf{3}\]

<p>We name the two players Player 0 and Player 1. Elements of the set \(\mathit{Players}\) identify players</p>

\[\mathit{Players} \defeq \{ 0, 1 \}\]

<p>In a typical game of tic-tac-toe, the players use the symbols \(X\) and \(O\) to mark their cells. In our version of tic-tac-toe each player uses its own symbol, either \(0\) or \(1\) to mark cells. An unmarked cell holds the symbol \(\_\). We let \(\mathit{Sym}\) denote the set of possible symbols at a cell:</p>

\[\mathit{Sym} \defeq \{ 0, 1, \_ \}\]

<p>The state of the board is then the set of functions from locations to symbols. We thus define the set of possible board states \(\mathit{Board}\) as</p>

\[\mathit{Board} \defeq \mathit{Sym}^\mathit{Loc}\]

<p>The dynamical system underlying our tic-tac-toe game stepper is then depicted as follows:</p>

<figure>
<img src="/assets/images/gameloop/tictactoe-full.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 11</figcaption>
</figure>

<p>It contains three yet undefined stateful subsystems: \(\mathit{Player0}\), \(\mathit{Player1}\), and \(\mathit{Environment}\). Intuitively, the game stepper advances in a periodic pattern consisting of steps of four types, in order:</p>

<ul>
  <li>\(\mathit{Environment}\) receives a move from \(\mathit{Player0}\) and executes its move</li>
  <li>\(\mathit{Environment}\) submits the resulting board to \(\mathit{Player1}\)</li>
  <li>\(\mathit{Environment}\) receives a move from \(\mathit{Player1}\) and executes its move</li>
  <li>\(\mathit{Environment}\) submits the resulting board to \(\mathit{Player0}\)</li>
</ul>

<p>In sets of the form \(1 + X\), the \(1\) component on the left is typically used to mean “inactive”. For example, on turns in which \(\mathit{Player0}\) submits its move, and on turns in which the environment submits the board to a player, \(\mathit{Player1}\) outputs \((0,\ast)\). Likewise, when \(\mathit{Environment}\) submits a board to \(\mathit{Player0}\), the demultiplexor outputs \((0, \ast)\) along the bottom channel leading to \(\mathit{Player1}\).</p>

<p>Note that players can submit any location to the environment as a move. However, if the cell at the submitted location is already occupied with either \(0\) or \(1\), then the \(\mathit{Environment}\) will choose not to perform the action and advance control to the next player without changing the board.</p>

<h2 id="environment">Environment</h2>

<p>We now define the \(\mathit{Environment}\) dynamical system. Our first task is deciding its set \(\mathit{State}_{\mathit{Environment}}\) of states. First, each state should convey the current execution step type</p>

\[\mathit{StepType} \defeq \{ \mathit{ReceiveFrom}(0), \mathit{SubmitTo}(0), \mathit{ReceiveFrom}(1), \mathit{SubmitTo}(1), \mathit{IllegalState} \}\]

<p>The \(\mathit{IllegalState}\) element above should be used when \(\mathit{Environment}\) receives an invalid input combination (i.e. one which we have prevented it from receiving by design). For those familiar with digital logic, this is somewhat analogous to a “don’t care” value.</p>

<p>Additionally, the state should convey the current board. We’ve already defined the set \(\mathit{Board}\) of board states above. Hence, our full state set is defined as</p>

\[\mathit{State}_{\mathit{Environment}} \defeq \mathit{StepType} \times \mathit{Board}\]

<p>As figure 11 shows, the environment’s output set is</p>

\[\mathit{Out}_{\mathit{Environment}} \defeq (1 + \mathit{Board}) \times \mathbf{3}\]

<p>The environment’s \(\mathit{output}_\mathit{Environment} : \mathit{State}_{\mathit{Environment}} \to \mathit{Out}_{\mathit{Environment}}\) function is then defined as</p>

\[\mathit{output}_\mathit{Environment} : \mathit{StepType} \times \mathit{Board} \to (1 + \mathit{Board}) \times \mathbf{3}\]

\[\mathit{output}_\mathit{Environment}(t, b) \defeq \begin{cases}
((1, b), n) &amp; \text{ if } t = SubmitTo(n) \\
((0, \ast), 2) &amp; \text{ if } t = ReceiveFrom(n)
\end{cases}\]

<p>Consulting figure 11, we see that</p>

\[\mathit{In}_{\mathit{Environment}} \defeq 1 + \mathit{Loc}\]

<p>For \(b \in \mathit{Board}\), we define \(b[\ell \mapsto n] \in \mathit{Board}\) as follows.</p>

\[b[\ell \mapsto n](k) \defeq \begin{cases}
b(k) &amp; \text{if } k \neq \ell \\
n &amp; \text{if } k = \ell
\end{cases}\]

<p>We define \(\mathit{nextState}_{\mathit{Environment}} : \mathit{In}_{\mathit{Environment}} \times \mathit{State}_{\mathit{Environment}} \to \mathit{State}_{\mathit{Environment}}\) as
\(~\\\)
\(\mathit{nextState}_{\mathit{Environment}} : (1 + \mathit{Loc}) \times \mathit{StepType} \times \mathit{Board} \to \mathit{StepType} \times \mathit{Board}\)
\(\mathit{nextState}_{\mathit{Environment}}((1,\ell), ReceiveFrom(n), b) \defeq \begin{cases}
(SubmitTo((n+1)~\%~2), b[\ell \mapsto n]) &amp; \text{if } b(\ell) = \_ \\
(SubmitTo((n+1)~\%~2), b) &amp; \text{otherwise}
\end{cases}\)
\(\mathit{nextState}_{\mathit{Environment}}((0,\ast), SubmitTo(n), b) \defeq (ReceiveFrom(n), b)\)</p>

<p>and for any other \((z,s,b) \in (1 + Loc) \times \mathit{StepType} \times Board\) we define
\(\mathit{nextState}_{\mathit{Environment}}(z,s,b) \defeq (\mathit{IllegalState}, b)\)</p>

<p>Finally, we define</p>

\[\mathit{Environment} : \vrt{\mathit{State}_{\mathit{Environment}}}{\mathit{State}_{\mathit{Environment}}} \leftrightarrows \vrt{\mathit{In}_{\mathit{Environment}}}{\mathit{Out}_{\mathit{Environment}}} \defeq \vrt{\mathit{nextState_{\mathit{Environment}}}}{\mathit{output}_{\mathit{Environment}}}\]

<h2 id="players">Players</h2>

<p>We define \(\mathit{Player0}\), eliding \(\mathit{Player1}\) as it is essentialy the same.</p>

<p>The state of the player systems can be used for two purposes. First, the state must record a \(Board\) whenever it is received from the environment. That way the player can use the board to compute a move on the next turn. Second, and optionally, a player’s state can serve as its brain by storing information about plan or strategy that the player is currently executing, or by storing an inferred mental model of the opposing player. We will keep things simple and decide moves in a stateless fashion, using only the current state of the board. Hence, we define</p>

\[\mathit{State}_{\mathit{Player0}} \defeq 1 + \mathit{Board}\]

<p>If the player’s state is \((1, b)\) then it has just received board \(b\) from the environment and is expected to submit a move on the next turn. Otherwise, the player’s state is \((0,\ast)\).</p>

<p>We can see from Diagram 11 that</p>

\[\mathit{In}_{\mathit{Player0}} \defeq 1 + \mathit{Board}\]

<p>and</p>

\[\mathit{Out}_{\mathit{Player0}} \defeq 1 + \mathit{Loc}\]

<p>Let \(\phi : \mathit{Board} \to \mathit{Loc}\) be player 0’s “strategy” for deciding a move given the current board; instead of defining it, we leave it as a parameter to the system.</p>

<p>We then define</p>

\[\mathit{output}_{\mathit{Player0}}(x) \defeq \begin{cases}
(0, \ast) &amp; \text{if } x = (0, \ast) \\
(1, \phi(b)) &amp; \text{if } x = (1, b)
\end{cases}\]

<p>and</p>

\[\mathit{nextState}_{\mathit{Player0}}((1, b), x) \defeq (1, b)\]

\[\mathit{nextState}_{\mathit{Player0}}((0, \ast), x) \defeq (0, \ast)\]

<p>The \(\mathit{Player0}\) dynamical system is then defined as</p>

\[\mathit{Player0} : \vrt{\mathit{State}_{\mathit{Player0}}}{\mathit{State}_{\mathit{Player0}}} \leftrightarrows \vrt{\mathit{In}_{\mathit{Player0}}}{\mathit{Out}_{\mathit{Player0}}} \defeq \vrt{\mathit{nextState}_{\mathit{Player0}}}{\mathit{output}_{\mathit{Player0}}}\]

<h2 id="putting-things-together">Putting things together</h2>

<p>Now that all of the components of our system have been defined, we will wire them together using the lens composition technique, expressing the system as a whole as a mathematical expression.</p>

<p>As a first step, we note that our system can be obtained by wiring together the two dynamical systems named \(A\) and \(B\) displayed below.</p>

<figure>
<img src="/assets/images/gameloop/tictactoe-full-ab.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 12</figcaption>
</figure>

<p>Where</p>

\[A \defeq \mathit{mux}(\mathit{Move}, 2) \circ (\mathit{Player0} \otimes \mathit{Player1})\]

<p>and</p>

\[B \defeq \mathit{demux}(\mathit{Board}, 2) \circ \mathit{Environment}\]

<p>Next, we take their parallel product \(A \otimes B\), which is depicted below.</p>

<figure>
<img src="/assets/images/gameloop/AB-juxtapose.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Figure 13</figcaption>
</figure>

<p>Finally, to close off our system, we must wire together the two components using lens composition, similar to how we wired together the \(\mathit{Clock}\) and \(\mathit{Meridiem}\) systems above.</p>

<p>We use the wiring lens</p>

\[\vrt{w^\sharp}{w} : \vrt{(1 + \mathit{Board}) \times (1 + \mathit{Board}) \times (1 + \mathit{Loc})}{(1 + \mathit{Loc}) \times (1 + \mathit{Board}) \times (1 + \mathit{Board})} \leftrightarrows \vrt{1}{1}\]

<p>where</p>

\[w(\ell, b_0, b_1) \defeq \ast\]

<p>and</p>

\[w^\sharp(\ell, b_0, b_1, \ast) \defeq (b_0, b_1, \ell)\]

<p>Our complete system is then equal to:</p>

\[\vrt{w^\sharp}{w} \circ (A \otimes B)\]

<h1 id="conclusion">Conclusion</h1>

<h2 id="evaluating-the-dynamical-systems-formalism">Evaluating the Dynamical Systems Formalism</h2>

<p>It’s worth taking a step back to ask whether the lens-based dynamical systems formalism is an appropriate tool for modelling turn-based computer games. The ability of lenses to represent cyclic data flow, from the players to the environment and back to the players, is essential. Additionally, lens based dynamical systems make it easy for us to encapsulate data, restricting a players to mutate only their own mental state, and restricting the environment to only mutate the physical world.</p>

<p>One drawback is that, due to the inherently concurrent nature of lens-based dynamical systems, we’ve needed to insert machinery for synchronization, which has little to do with dynamics of our turn-based games. For example, giving most wires the type \(1 + X\) is a distraction.</p>

<h2 id="looking-ahead">Looking ahead</h2>

<p>Now that we’ve developed a mathematical model of a game stepper for tic-tac-toe, let’s recall the significant features listed at the end of my <a href="/posts/2025/07/11/towards-mathematical-model.html">previous post</a> and consider how well the model implements these features.</p>

<ul>
  <li>✅ A robot performs physical actions by submitting requests to an environment. The environment decides whether to honor these requests.</li>
  <li>✅ A robot has internal state, but it’s a purely “mental” state that is used to make decisions. Physical properties of the robot are stored in the environment’s internal state.</li>
  <li>❌ A robot may send a message to another robot, which represents information sent along some physical communication medium.</li>
</ul>

<p>Our model implements the first two features. The game board can be seen as the environment, which encapsulates all physical information, namely the contents of every cell on the game board. A player can be seen as a robot; by virtue of being a dynamical systems, it encapsulates its own private data, i.e. mental state.</p>

<p>The last feature, message passing among robots, is not present in the model I described. Speculating, in a game’s source code, message passing might look similar to the following pseudo-code.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// When the player switches off the fuse box, this channel notifies all subscribers.
channel fuse_box_off : 1;

robot roy {
  receives on fuse_box_off;

  state working {
    handler fuse_box_off (_ : 1) = {
      set_state(fix_fusebox);
    }
  }

  state fix_fusebox {
    ...
  }
}

robot fuse_box {
  sends on fuse_box_off;

  state on {
    handler on_player_touch (_ : 1) = {
      send fuse_box_off(*);
      set_state(off);
    }
  }

  state off {
    ...
  }
}
</code></pre></div></div>

<p>Our program starts with a list of channel declarations. A channel declaration includes both a name and the type of messages sent along the channel. In this example, our channel is named <code class="language-plaintext highlighter-rouge">fuse_box_off</code> and has type \(1\), where \(1\) is the type of containing a single information-free value \(\ast\).</p>

<p>Each robot is implemented as a state machine. A robot definition begins with a list of declarations stating which channels the robot may send and receive upon. Next, the robot defines a list of states. These states can declare <em>handlers</em> to provide code that executes when a message is received, and the handlers in turn can issue <code class="language-plaintext highlighter-rouge">send</code> commands, which broadcast values to all of the subscribers of a channel.</p>

<p>If a robot sends a message along a channel, when is the message received by the channel’s subscribers? Our answer is that it is received on the next frame. The reason for this is that all robots acting on a frame are assumed to be acting at roughly the same time: times so close together that their difference is considered too fine-grained for our game engine to track.</p>

<p>A game engine may very reasonably execute multiple robot scripts in sequence on a single frame, but having the second robot receive messages sent by the first robot on the same frame is problematic. Not only does it violate our intuition that all robots are executing “at the same time” on a single frame, but it creates a hidden rule where a message sent from one robot to another may or may not arrive until the next frame depending on which robot was processed first.</p>

<p>If two robots transmit messages along the same channel on the same frame, which message do the channel’s subscribers process first? Since both messages are considered to be sent “at the same time,” our game system is too coarse-grained to answer this question. Our model should therefore non-deterministically permit any ordering. However, our current dynamical system formalism doesn’t support non-determinism.</p>

<p>The next blog post will correct this by extending the formalism with non-deterministic state transitions. It will also present a basic model of MegaZeux where all robots operate concurrently at every frame. We won’t have time to model message channels in that post, but by introducing non-determinism into the MegaZeux model, we will establish the foundation needed to add message passing in a subsequent post.</p>

<hr />

<p><strong>Next:</strong> <a href="/2025/11/04/modelling-megazeux.html">Modelling MegaZeux</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[\(\newcommand{vrt}[2]{\left ( \begin{array}{l} #1 \\ #2 \end{array} \right )}\) \(\newcommand{defeq}{\overset{\mathit{def}}{=}}\) \(\newcommand{am}{\text{a.m.}}\) \(\newcommand{pm}{\text{p.m.}}\)]]></summary></entry><entry><title type="html">Towards a Mathematical Model of Computer Games</title><link href="/posts/2025/07/11/towards-mathematical-model.html" rel="alternate" type="text/html" title="Towards a Mathematical Model of Computer Games" /><published>2025-07-11T20:56:48-07:00</published><updated>2025-07-11T20:56:48-07:00</updated><id>/posts/2025/07/11/towards-mathematical-model</id><content type="html" xml:base="/posts/2025/07/11/towards-mathematical-model.html"><![CDATA[<h1 id="seeking-a-mathematical-model-of-computer-games">Seeking a mathematical model of computer games</h1>

<p>Many years ago, I worked in the computer game industry as a gameplay programmer. My intuition was that the languages I used, C++ and Lua, were not suitable for gameplay programming.</p>

<p>There were a few reasons for this. First, not only did C++ and Lua lack in-built notions of space and time, but they also lacked general purpose features for reasoning about them. For example, I could represent a 3D vector as an object in C++, but the C++ type system had no means to specify which basis (a.k.a. “coordinate system”) the vector belonged to, making it easy to perform the invalid operation of adding two vectors belonging to different bases. Second, despite game characters dynamically adjusting their goals in response to stimulus from their environment, C++ and Lua had no in-built notion of things like imperfect perception and goal setting.</p>

<p>It would be fallacious to claim that the above features are better off built in to a language instead of implemented using general purpose features. In most mainstream languages, we can implement some sort of state machine system for controlling game characters, where each state represents a distinct goal that a character is pursuing. We <em>could</em> tag each vector with a basis identifier, and tag each point with its affine frame, dynamically enforcing proper usage at runtime. Perhaps we could even use some sort of indexed type system to enforce proper vector operations statically, though I’m not sure if any mainstream languages are capable of this.</p>

<p>Nonetheless, I think it’s worth experimenting with the design of game specific languages. Even if it turns out that the abstractions of general purpose languages are sufficient for game specific needs, our game specific experimentation may clarify exactly what is needed and how it should be structured.</p>

<p>There are a few ways we could go about experimenting with game specific languages:</p>

<ul>
  <li>
    <p>Implement a real game specific language that compiles to executable games. This would require an enormous amount of work. We would evaluate our experiment by using our language to create games. This too would require an enormous amount of work. The iteration time for this approach is simply too lengthy to be an effective form of experimentation.</p>
  </li>
  <li>
    <p>Model computer games, or simplified approximations of computer games, as mathematical objects. Then design a language that compiles to such mathematical objects. Evaluate our language by designing a logical system to reason about the game models. If this logic is expressive, we evaluate the language positively, because it implies that humans can reason about it easily.</p>
  </li>
</ul>

<p>The first approach has the advantage of being real, while the second approach provides deeper understanding and faster iteration times. In this series of posts, I’m going to pursue the second approach, but I’m only going to take the first step: <strong>I will model computer games, or simplified approximations of computer games, as mathematical objects.</strong> I’ve never created mathematical models of computer games before, so I’m going to try modelling some of the simplest games I can find that still feature space, time, and interacting agents. To this end, I’ve chosen to use a 90s game creation system called <em>MegaZeux</em> as an inspiration for my model. The convenient thing about MegaZeux is that, despite feeling like a standard real-time computer game, its time and space are discrete and can therefore be modeled entirely by integers rather than floating point numbers. I will present my model using elementary mathematics; it should be accessible to anyone who knows what sets, functions, set-builder notation, and cartesian products are.</p>

<h1 id="understanding-the-problem">Understanding the problem</h1>

<p>This post is going to analyze MegaZeux using intuition rather than rigor, trying to isolate the essence of what a MegaZeux game is. It will specifically focus on how multiple simulated agents interact with other agents and the game world, identifying some fundamental features of gameplay programming by exploring a concrete scenario in a MegaZeux game called <em>Weirdness</em>.</p>

<p>The primary purpose of this post is to motivate my next few posts, in which I create a mathematical model of a MegaZeux-style computer game. However, it might also be a fun read for people who are interested in computer games and have never heard of MegaZeux, or gaming fans who want to consider computer games from an analytical perspective.</p>

<h2 id="megazeux">MegaZeux</h2>

<p><em>MegaZeux</em> is a game creation system from the 90s, whose games take place on a grid of 8x14 pixel images. That’s right: in a typical MegaZeux game, every significant object, whether a goblin, a wall, or a tree, is depicted using an 8x14 image. This extreme constraint comes from DOS text-mode graphics, where textual documents were displayed in grids of 8x14 pixel characters. While 8x14 might be a reasonable size to depict a single letter of the Roman alphabet, depicting something more complex, like a human, is much more challenging. As a result, players do not expect the graphics of a MegaZeux game to look good. For a game developer, depicting a game world using simple abstract art rather than poring over complex visual details greatly reduces the effort used to bring a game world to life.</p>

<p>In MegaZeux, scriptable game characters are idosyncratically called <em>robots</em>. However, we will often refer to them as agents. Each robot is controlled by a <em>robotic script</em>. Because robotic scripting is not the state of the art in game character scripting, I will intentionally avoid discussing it comprehensively. I care about what robotic scripting accomplishes rather than how robotic scripting works.</p>

<p>Here are a few examples of MegaZeux games:</p>

<p><img src="/assets/images/gameloop/mzx-depot-dungeons.png" /></p>

<p><a href="https://www.digitalmzx.com/show.php?id=2097">Depot Dungeons</a> is a puzzle game where the player must traverse a dungeon while solving puzzles involving lever pulling and crate pushing, all the while fighting off aggressive mutant cockroaches.</p>

<p><img src="/assets/images/gameloop/mzx-kikan-intro.png" /></p>

<p><a href="https://www.digitalmzx.com/show.php?id=1539">Kikan</a> is a turn based, story driven RPG similar to games in the Final Fantasy series. Unlike most RPGs, it features a semi-realistic modern setting.</p>

<h2 id="roy-a-typical-gameplay-scenario">Roy: A Typical Gameplay Scenario</h2>

<p>It’s extraordinary that MegaZeux was created by a high school kid, Alexis Janson. In addition to creating <em>MegaZeux</em>, she used <em>MegaZeux</em> to create the <em>Zeux</em> series of action adventure games. Then, she created her final <em>MegaZeux</em> game, <em>Weirdness</em>. <em>Weirdness</em> is a puzzle adventure that pushes <em>MegaZeux</em> scripting system to its limits, featuring complex character behaviors and even a first-person maze.</p>

<p>A typical game scripting scenario can be found at the beginning of <em>Weirdness</em>. A character named Roy sits at his computer in his house. If the player touches him, he says “Not now, Jace, I’m busy making UltraZeux games”.</p>

<p><img src="/assets/images/gameloop/mzx-weirdness-roy-computer.png" /></p>

<p>If the player goes into the basement, he can turn off the fuse box, causing the lights in the house to shut off and destroying Roy’s UltraZeux work.</p>

<p><img src="/assets/images/gameloop/mzx-weirdness-fusebox-off.png" /></p>

<p>Roy then walks into the basement and turns the fuse box back on.</p>

<p><img src="/assets/images/gameloop/mzx-weirdness-fusebox-on.png" /></p>

<p>In this scenario, the fuse box itself is a robot. Each robot has a <em>robotic script</em>, which is a program pairing several <em>labels</em>, which are names of events to respond to, with <em>handlers</em>, which are sequences of instructions that the robot should execute in response to these events. When the player attempts to move into the grid cell occupied by the fuse box, the game triggers the fuse box script’s “touch” handler, which spawns a dialog asking the player if they want to turn the fuse box off. If they choose “yes” then another handler inside the fuse box’s script is executed. This handler sends a “fuse box off” message to Roy. Upon receiving the “fuse box off” message, Roy’s robotic script executes its “fuse box off” handler, causing him to express his frustration and walk into the basement to turn the fuse box back on.</p>

<p>Let’s take a step back and think about what’s going on here, using intuition rather than deep analysis. <em>MegaZeux</em> is simulating the physical world in a rough manner. The robots in this scenario, Roy and the fuse box, represent physical things in the world. Robotic scripts are an abstraction of the physical things’ “brains”: both actual brains, as in the case of Roy, and pseudo brains, as in the case of the fuse box. A pseudo brain is a subset of a physical object’s characteristics that determine how the object interacts with other objects. But a pseudo brain only includes physical characteristics too fine grained to fall within the scope of the game system, thus requiring custom code; in this sense, a brain is a specific type of pseudo brain. For example, the fuse box occupies a grid cell at a (row,column) location understood by the game system. But the position of the switch <em>within</em> the cell is too fine grained and therefore must be dealt with using <em>Weirdness</em>-specific pseudo brain code, a robotic script.</p>

<p>Each handler in a robotic script issues commands instructing its robot to interact with the world in various ways. For example, <code class="language-plaintext highlighter-rouge">go SOUTH</code> instructs the robot Roy to attempt walking to the grid cell whose \(y\)-coordinate is one greater than Roy’s current \(y\)-coordinate. This will only happen if the cell to the south of Roy is currently unoccupied. For this reason, we can view commands such as <code class="language-plaintext highlighter-rouge">go SOUTH</code> as a message sent from Roy’s brain to the physical world, which we will call the <em>environment</em>. Upon receiving the message, the environment may or may not choose to move Roy, depending on whether such movement is compatible with its laws of physics, which are <em>dictated by the environment</em>. For example, a request by Roy to move into a cell occupied by a wall would be rejected by the environment, because the environment’s laws of physics do not allow a robot and a wall to occupy the same grid cell.</p>

<p>From this discussion, we extract some key features we would like to model.</p>
<ul>
  <li>Robots that affect the physical world by making requests to an environment. The environment may or may not honor these requests at its discretion.</li>
  <li>A specific type of request a Robot can make to the environment is <em>message sending</em> to another agent, as when the fuse box sends the “fuse box off” message to Roy</li>
  <li>Agents receive messages from the environment and other agents; these message may affect their behavior. The environment can be viewed as a mediator, so that all messages received by robot \(B\) from robot \(A\) can be viewed as coming directly from the environment and indirectly from robot \(B\).</li>
</ul>

<h1 id="computer-games-as-dynamical-systems">Computer games as dynamical systems</h1>

<p>Now that we’ve highlighted the features that we wish to focus on modelling by taking inspiration from <em>MegaZeux</em> and <em>Weirdness</em>, let’s consider the structure of a computer game.</p>

<figure>
<img src="/assets/images/gameloop/game-system.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Diagram 1</figcaption>
</figure>

<p>We can view the game’s state as encapsulated in the game stepper; nothing outside of the game stepper may modify its internal state. The game evolves over a sequence of discrete time steps. At each time step, the game stepper must compute two quantities.</p>

<ul>
  <li>From the game’s current state, the game stepper must compute its output, a matrix of color values to display to the screen.</li>
  <li>The game stepper must also compute the game’s next state from its input and its current state.  Its input might be a mapping from key identifiers to booleans indicating whether each key is pressed. The game’s state might contain a matrix of physical locations, where each location contains an identifier denoting either a game character, a wall, or an empty space.</li>
</ul>

<p>Put differently, the game stepper is a pair of two functions</p>

\[\mathit{output} : \mathit{GameState} \to \mathit{Output}\]

<p>and</p>

\[\mathit{nextState} : \mathit{Input} \times \mathit{GameState} \to \mathit{GameState}\]

<p>Such a system is called <em>open</em>, because the source of the \(\mathit{Input}\) wire and the destination of the \(\mathit{Output}\) wire are left unspecified.</p>

<p>Computing the \(\mathit{output}\) function is often called <em>computer graphics</em>.
From the discussion above, you may have inferred that computer graphics is not what I’m interested in, nor am I interested in processing the input. The perspective I’d like to take on computer games actually looks more like this:</p>

<figure>
<img src="/assets/images/gameloop/game-closed-system.drawio.png" style="margin-top: 30px; margin-bottom: 30px" />
<figcaption>Diagram 2</figcaption>
</figure>

<p>Without input or output, what we have is more of a closed simulation than a game. Now, at each time step, the game stepper no longer computes an output. It still must compute a next state. But because it no longer receives input, only its current state is used to compute its next state. So this diagram depicts a function from game states to game states.</p>

\[\mathit{nextState} : \mathit{GameState} \to \mathit{GameState}\]

<p>Let \(1\) be the singleton set \(\{ \ast \}\), where \(\ast\) is some non-descript set element.
A closed simulation is essentially just a special case of an open one, where both \(\mathit{Input}\) and \(\mathit{Output}\) are equal to the set \(1\).</p>

\[\mathit{output} : \mathit{GameState} \to 1\]

<p>and</p>

\[\mathit{nextState} : 1 \times \mathit{GameState} \to \mathit{GameState}\]

<p>The idea here is that computing an output in the set \(1\) is equivalent to not computing an output at all, because choosing an element of a one-element set does not involve making a decision. Likewise an element of \((\ast, s)\) of \(1 \times \mathit{GameState}\) is equivalent to \(s\) since \(\ast\) is the only choice for the first component of the pair.</p>

<p>A box doesn’t seem very interesting as a diagram. It becomes interesting when we compose it from stateful subcomponents. Each subcomponent is a dynamical system that transforms its current state into output, and also transforms input and an internal state into a next internal state at each point in a sequence of time steps.</p>

<p>What are the stateful subcomponents? As a first approximation, they are</p>

<ul>
  <li>The environment, whose state consists of the grid of available and occupied cells</li>
  <li>The robots. The internal state of the fuse box may track whether it is on or off. The internal state of Roy may contain a program counter that determines which of the instructions such as <code class="language-plaintext highlighter-rouge">go SOUTH</code> or <code class="language-plaintext highlighter-rouge">go EAST</code> he will perform at the next time step.</li>
</ul>

<p>Note that the position of each robot is part of the simulated “physical world” and is thus contained in the internal state of the environment rather than the internal state of the robot itself. This is why a robot can only make a <em>request</em> to move to an adjacent grid cell, and it is ultimately the environment’s decision whether or not to honor that request.</p>

<h1 id="conclusion">Conclusion</h1>

<p>We’ve examined MegaZeux’s <em>robot</em> system, which is used to simulate complex objects, both sentient and non-sentient, interacting in a simulated world. Some notable features are:</p>

<ul>
  <li>A robot performs physical actions by submitting requests to an environment. The environment decides whether to honor these requests.</li>
  <li>A robot has internal state, but it’s a purely “mental” state that is used to make decisions. Physical properties of the robot are stored in the environment’s internal state.</li>
  <li>A robot may send a message to another robot, which represents information sent along some physical communication medium.</li>
</ul>

<p>In my next post, I will define a game stepper for tic-tac-toe, which resembles MegaZeux in a few different ways</p>

<ul>
  <li>The environment is the game board.</li>
  <li>The two players, like robots, submit requests to the environment. Their internal state can be used for planning and decision making, but is isolated from the physical rules of the game board.</li>
</ul>

<p>Just for fun, I will leave you with the source code for the robot Roy from Weirdness. Reading it is optional. It demonstrates what I’m trying to avoid. The code that controls a robot or agent should communicate intent to the reader. Its evolution over time and interactions with the world should be formally summarizable with assertions. It should provide high level constructs to perform complex tasks simply. Implementing Roy using a modern state machine or behavior tree system would improve things in this direction, but by having a mathematical model of the agents and the environment they interact with, I think we can improve things even more.</p>

<details>
<summary>Roy's Robotic Script (Click to expand)</summary>
<p style="white-space:pre-line;background-color:lightgray;">: "do"
set "loopcount" to random 140 to 142
char "loopcount"
wait for 2
goto "do"
: "touch"
* "~5Roy: Not now, Jace, I'm busy making UltraZeux games."
send "msg" to "fad"
goto "do"
: "fboff"
lockself
char 'ç'
wait for 25
* "~5Roy: $%#&amp;&amp;*! I haven't saved my game yet!"
send "msg" to "fad"
: "fboff2"
wait for 45
char 'á'
cycle 2
* "~5Roy: I'd better go check the fuse box..."
send "msg" to "fad"
go SOUTH for 3
: "mv1r"
if touching SOUTH then "mv1"
go SOUTH for 1
go WEST for 2
: "mv2r"
if touching WEST then "mv2"
go WEST for 1
: "dr1r"
if c?? Space p?? at WEST then "dr1"
if touching WEST then "mvx5"
open at WEST
wait for 1
color c8e
go WEST for 4
go SOUTH for 8
rel to self
: "mv4r"
if player at 222 -12 "mv4"
rel to self
gotoxy 222 -12
go SOUTH for 7
go WEST for 12
: "dr2r"
if c?? Space p?? at NORTH then "dr2"
if touching NORTH then "mvx6"
open at NORTH
wait for 1
go NORTH for 4
go EAST for 6
: "mv5r"
if touching EAST then "mv5"
go EAST for 1
rel to self
: "mv6r"
if player at 74 0 "mv6"
rel to self
gotoxy 74 0
go WEST for 11
: "mv7r"
if touching WEST then "mv7"
go WEST for 1
wait for 10
if "darkness" = 0 then "noprob"
if "wire" = 1 then "nowire"
* "~5Roy: Ahh, here's the problem."
send "msg" to "fad"
wait for 10
send at WEST to "fix"
wait for 5
: "noprobr"
go EAST for 11
: "mv8r"
if touching EAST then "mv8"
go EAST for 1
rel to self
: "mv9r"
if player at -74 0 "mv9"
rel to self
gotoxy -74 0
go WEST for 7
: "mvx1r"
if touching SOUTH then "mvx1"
go SOUTH for 1
: "mvx2r"
if touching SOUTH then "mvx2"
: "dr4r"
if c?? OpenDoor p?? at SOUTH then "dr3"
rel to self
if c?? OpenDoor p?? at -1 1 then "dr4"
go SOUTH for 1
put c0f Door p04 to SOUTH
open at SOUTH
wait for 1
go SOUTH for 2
if "tostore" = 1 then "toss"
go EAST for 12
go NORTH for 7
rel to self
: "mvBr"
if player at -222 12 "mvB"
rel to self
gotoxy -222 12
go NORTH for 7
: "mvCr"
if touching NORTH then "mvC"
go NORTH for 1
: "mvx3r"
if touching EAST then "mvx3"
go EAST for 1
: "mvx4r"
if touching EAST then "mvx4"
: "dr6r"
if c?? OpenDoor p?? at EAST then "dr5"
rel to self
if c?? OpenDoor p?? at 1 1 then "dr6"
go EAST for 1
put c0f Door p03 to EAST
open at EAST
color c1e
wait for 1
go EAST for 5
go NORTH for 4
cycle 1
send "dthing" to "check"
unlockself
if "darkness" = 1 then "fboff2"
goto "do"
: "mvx1"
cycle 1
move player to EAST
cycle 2
goto "mvx1r"
: "mvx2"
cycle 1
move player to EAST
cycle 2
goto "mvx2r"
: "mvx3"
cycle 1
move player to SOUTH
cycle 2
goto "mvx3r"
: "mvx4"
cycle 1
put player SOUTH
cycle 2
goto "mvx4r"
: "mvx5"
cycle 1
put player EAST
cycle 2
goto "dr1"
: "mvx6"
cycle 1
put player SOUTH
cycle 2
goto "dr2"
: "dr1"
rel to self
put c01 Floor p?? at -2 0
rel to self
put c01 Floor p?? at -2 1
put c0f Door p05 to WEST
goto "dr1r"
: "dr2"
rel to self
put c04 Floor p?? at 0 -2
rel to self
put c04 Floor p?? at -1 -2
put c0f Door p00 to NORTH
goto "dr2r"
: "dr3"
: "dr4"
rel to self
put c04 Floor p?? at -1 1
put c04 Floor p?? to SOUTH
rel to self
put c0f Door p04 at 0 2
goto "dr4r"
: "dr5"
: "dr6"
rel to self
put c01 Floor p?? at 1 1
put c01 Floor p?? to EAST
rel to self
put c0f Door p03 at 2 0
goto "dr6r"
: "mv1"
cycle 1
move player to EAST
cycle 2
goto "mv1r"
: "mv2"
cycle 1
move player to NORTH
cycle 2
goto "mv2r"
: "mv4"
cycle 1
move player to WEST
cycle 2
goto "mv4r"
: "mv5"
cycle 1
move player to SOUTH
cycle 2
goto "mv5r"
: "mv6"
cycle 1
move player to NORTH
cycle 2
goto "mv6r"
: "mv7"
cycle 1
move player to NORTH
cycle 2
goto "mv7r"
: "mv8"
cycle 1
move player to NORTH
cycle 2
goto "mv8r"
: "mv9"
cycle 1
move player to SOUTH
cycle 2
goto "mv9r"
: "mvB"
cycle 1
move player to WEST
cycle 2
goto "mvBr"
: "mvC"
cycle 1
move player to WEST
cycle 2
goto "mvCr"
: "noprob"
* "~5Roy: Hmmm... nothing wrong here."
send "msg" to "fad"
wait for 15
goto "noprobr"
: "nowire"
* "~5Roy: Is this somebody's idea of a joke!?"
send "msg" to "fad"
wait for 15
* "~5Roy: I guess I'll go buy a new wire..."
send "msg" to "fad"
wait for 5
set "tostore" to 1
goto "noprobr"
: "toss"
go SOUTH for 3
: "ts1r"
if touching SOUTH then "ts1"
go SOUTH for 1
* "~5Roy: I'll be back later, Jace, DON'T touch my computer!"
send "msg" to "fad"
send "dthing" to "check"
set "tostore" to 0
die
: "ts1"
cycle 1
move player to EAST
cycle 2
goto "ts1r"
</p>
</details>

<hr />

<p><strong>Next:</strong> <a href="/2025/10/18/modelling-tic-tac-toe.html">Modelling Tic-Tac-Toe</a></p>]]></content><author><name></name></author><category term="posts" /><summary type="html"><![CDATA[Seeking a mathematical model of computer games]]></summary></entry></feed>